{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7R5vXVmxf97"
      },
      "outputs": [],
      "source": [
        " from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaSsapUK_LMK"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uj1ug6NAxks9"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup & Config\n",
        "import transformers\n",
        "from transformers import RobertaModel, RobertaTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "y8nlHou7pCQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_zI7KW3xkyS"
      },
      "outputs": [],
      "source": [
        "#import torch\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZIbVXh1xk1f"
      },
      "outputs": [],
      "source": [
        "model_name_or_path = \"albert-xxlarge-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name_or_path)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPZ8ldIoxk4U"
      },
      "outputs": [],
      "source": [
        "mask_sentence = f\"\"\"Photogallery - 'Dragon Ball Super' Goku can [MASK] Super Saiyan Blue Ultra-Instinct\"\"\"\n",
        "\n",
        "mask_input = tokenizer.encode(mask_sentence, return_tensors=\"pt\").to(device)\n",
        "cands=[]\n",
        "logits = model(mask_input)[0].squeeze().detach()\n",
        "is_masked = torch.where(mask_input == tokenizer.mask_token_id, 1, 0)\n",
        "masked_idxs = torch.nonzero(is_masked)\n",
        "probs= torch.softmax(logits[masked_idxs[:,1]], dim=1)\n",
        "\n",
        "top_vocab_idxes = torch.topk(probs, 200)\n",
        "for token_id in torch.transpose(top_vocab_idxes[1], 1, 0):\n",
        "    cands.append(tokenizer.decode(token_id))\n",
        "    print(token_id, \"->\", tokenizer.decode(token_id))\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KE8DOrwR94Yr"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import re\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTCrkXWClCGP"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PoylgxzlOWU"
      },
      "outputs": [],
      "source": [
        "df['metaphorical_cands']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRTLy_MWxk7Y"
      },
      "outputs": [],
      "source": [
        "cands=[]\n",
        "for index,row in tqdm(df.iterrows()):\n",
        "  cands2=[]\n",
        "  mask_sentence = row['Text']\n",
        "  print(row['Text'])\n",
        "  #svos=row['svo']\n",
        "  verb=row['ROOT']\n",
        "  verb=re.sub('[^A-Za-z0-9]+', '', verb)\n",
        "  insensitive_rep = re.compile(re.escape(verb), re.IGNORECASE)\n",
        "  mask_sentence=insensitive_rep.sub(\"[MASK]\", mask_sentence)\n",
        "  #mask_sentence=mask_sentence.replace(verb,'[MASK]')\n",
        "  mask_input = tokenizer.encode(mask_sentence, return_tensors=\"pt\").to(device)\n",
        "  logits = model(mask_input)[0].squeeze().detach()\n",
        "  is_masked = torch.where(mask_input == tokenizer.mask_token_id, 1, 0)\n",
        "  masked_idxs = torch.nonzero(is_masked)\n",
        "  probs= torch.softmax(logits[masked_idxs[:,1]], dim=1)\n",
        "  top_vocab_idxes = torch.topk(probs, 200)\n",
        "  for token_id in torch.transpose(top_vocab_idxes[1], 1, 0):\n",
        "      cands2.append(tokenizer.decode(token_id))\n",
        "      if index == 2:\n",
        "        print(token_id, \"->\", tokenizer.decode(token_id))\n",
        "  cands.append(cands2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cands=[]\n",
        "for index,row in tqdm(df.iterrows()):\n",
        "  cands2=[]\n",
        "  mask_sentence = row['Text']\n",
        "  print(row['Text'])\n",
        "  mask_input = tokenizer.encode(mask_sentence, return_tensors=\"pt\").to(device)\n",
        "  logits = model(mask_input)[0].squeeze().detach()\n",
        "  is_masked = torch.where(mask_input == tokenizer.mask_token_id, 1, 0)\n",
        "  masked_idxs = torch.nonzero(is_masked)\n",
        "  probs= torch.softmax(logits[masked_idxs[:,1]], dim=1)\n",
        "  top_vocab_idxes = torch.topk(probs, 200)\n",
        "  for token_id in torch.transpose(top_vocab_idxes[1], 1, 0):\n",
        "      cands2.append(tokenizer.decode(token_id))\n",
        "      if index == 1:\n",
        "       # print(token_id)\n",
        "        print(mask_sentence)\n",
        "        print(token_id, \"->\", tokenizer.decode(token_id))\n",
        "  cands.append(cands2)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yn4_BpxSzlUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cands[0:5]"
      ],
      "metadata": {
        "id": "brntPYQC-xcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA4tFM5Qxk-U"
      },
      "outputs": [],
      "source": [
        "df['candidates']=cands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rU8sUXikxlBi"
      },
      "outputs": [],
      "source": [
        "df.to_csv('',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFTe4M1lxlEu"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yi8heWJ0xlIK"
      },
      "outputs": [],
      "source": [
        "############################\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZQBKYnSCYCz"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Ee96CmI0vHdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5WDhMYDxlOo"
      },
      "outputs": [],
      "source": [
        "classNames = ['literal' ,'metaphorical']\n",
        "PRE_TRAINED_MODEL_NAME = 'roberta-base'\n",
        "tokenizer2 = RobertaTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bD3TKbrM8Qq6"
      },
      "outputs": [],
      "source": [
        "class MetaphorDataset(Dataset):\n",
        "\n",
        "  def __init__(self, tweet_text, targets, tokenizer2, max_len):\n",
        "    self.tweet_text = tweet_text\n",
        "    self.targets = targets\n",
        "    self.tokenizer2 = tokenizer2\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.tweet_text)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    tweet = str(self.tweet_text[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer2.encode_plus(\n",
        "      tweet,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      padding='max_length',\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "      truncation=True\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'tweet_text': tweet,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFdG60YK8Qt_"
      },
      "outputs": [],
      "source": [
        "class MetaphorClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(MetaphorClassifier, self).__init__()\n",
        "    self.roberta = RobertaModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.roberta.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.roberta(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      return_dict=False\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlSdmDKU8Qxi"
      },
      "outputs": [],
      "source": [
        "model2 = MetaphorClassifier(len(classNames))\n",
        "model2 = model2.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiU5yWMa8Q1C"
      },
      "outputs": [],
      "source": [
        "state_dict = torch.load('best_model_state_v5.pth')\n",
        "model2.load_state_dict(state_dict)\n",
        "model2=model2.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsAqhQn-xlSL"
      },
      "outputs": [],
      "source": [
        "class_names = ['literal' ,'metaphorical']\n",
        "BATCH_SIZE = 16\n",
        "MAX_LEN = 80\n",
        "EPOCHS = 7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import re"
      ],
      "metadata": {
        "id": "em3lJEs82VYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"candidates\"] = df[\"candidates\"].apply(eval)"
      ],
      "metadata": {
        "id": "wgp02eLOhBq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "814Cfov_xlVg"
      },
      "outputs": [],
      "source": [
        "literal_cands=[]\n",
        "count_l=[]\n",
        "count_m=[]\n",
        "metaphorical_cands=[]\n",
        "for index,row in tqdm(df.iterrows()):\n",
        "  literal=[]\n",
        "  metaphorical=[]\n",
        "  tweet_text2 = row['Text']\n",
        "  #svos=row['svo']\n",
        "  verb=row['ROOT']\n",
        "  verb=re.sub('[^A-Za-z0-9]+', '', verb)\n",
        "  insensitive_rep = re.compile(re.escape(verb), re.IGNORECASE)\n",
        "  tweet_text2=insensitive_rep.sub(\"<mask>\", tweet_text2)\n",
        "  cands=row['candidates']\n",
        "  i=0\n",
        "  j=0\n",
        "\n",
        "  for word in cands:\n",
        "    tweet_text=tweet_text2.replace('<mask>',word)\n",
        "    encoded_review = tokenizer2.encode_plus(\n",
        "      tweet_text,\n",
        "      max_length=MAX_LEN,\n",
        "      add_special_tokens=True,\n",
        "      return_token_type_ids=False,\n",
        "      truncation=True,\n",
        "      padding='max_length',\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "    input_ids = encoded_review['input_ids'].to(device)\n",
        "    attention_mask = encoded_review['attention_mask'].to(device)\n",
        "    model2.eval()\n",
        "\n",
        "    model2.zero_grad()\n",
        "\n",
        "    output = model2(input_ids, attention_mask)\n",
        "    _, prediction = torch.max(output, dim=1)\n",
        "    if class_names[prediction] =='literal':\n",
        "      i+=1\n",
        "      literal.append(word)\n",
        "      \n",
        "    elif class_names[prediction]=='metaphorical':\n",
        "      metaphorical.append(word)\n",
        "      \n",
        "      j+=1\n",
        "      if i>=25 and j>=25:\n",
        "        break\n",
        "  count_l.append(i)\n",
        "  count_m.append(j)\n",
        "  literal_cands.append(literal)\n",
        "  metaphorical_cands.append(metaphorical)\n",
        "     \n",
        "\n",
        "  \n",
        "  \n",
        "     \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agoLLX4txlYN"
      },
      "outputs": [],
      "source": [
        "df2=df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2['literal_cands']=literal_cands"
      ],
      "metadata": {
        "id": "Q_xP_ohB5oXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['metaphorical_cands']=metaphorical_cands"
      ],
      "metadata": {
        "id": "S4rbtEuI5v9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['count_l']=count_l"
      ],
      "metadata": {
        "id": "uYLTwMZrJVXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['count_m']=count_m"
      ],
      "metadata": {
        "id": "bfEaZAnmJZER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.to_csv('corrected_cands_meta.csv',index=False)"
      ],
      "metadata": {
        "id": "NJD7NtGMJ0yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metaphorical_cands"
      ],
      "metadata": {
        "id": "o1Nt1UzKJbnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xqyGmCesJ4nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.to_csv('',index=False)"
      ],
      "metadata": {
        "id": "w3Wl7E5R50dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['literal_cands']"
      ],
      "metadata": {
        "id": "XjO_cPH92wyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Text'][1302]"
      ],
      "metadata": {
        "id": "D0dmr1UAiNnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cands2.append(cands)"
      ],
      "metadata": {
        "id": "LaeSBzYS7dia"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}